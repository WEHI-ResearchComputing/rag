<h2><span class="fontColorThemeSecondary">SLURM Partitions</span></h2><p>Partitions are logical sets of nodes that have different assortments of constraints such as job size limit, job time limit, users permitted to use it, etc. Initial design of SLURM Partitions were based on <a href="/:w:/s/ResearchComputingSteeringGroup/EUVFW2QYPpFPuZ9758fvOtUBYA7GSei7NkUVr-QM0actEg?e=4FzI5f"><strong>researchers' requirement</strong></a> gathered in 2020. Continuous&nbsp;changes to SLURM are announced <a href="/sites/rc2/SitePages/SLURM-Changes.aspx"><strong>here</strong></a>.</p><p>By default, jobs will be submitted to the "regular" partition. To submit your job to another partition, make use of the "--partition" Slurm option.</p><p>Milton SLURM has the following partitions:</p><figure class="table canvasRteResponsiveTable" style="width:1146px;" title="Table"><table class="filledHeaderTableStyleTheme ck-table-resized"><colgroup><col style="width:15.18%;"><col style="width:84.82%;"></colgroup><tbody><tr><td>Partition name</td><td><p style="text-align:center;">Description</p></td></tr><tr><td><span class="fontColorBlue"><strong>interactive</strong></span></td><td>This queue is mainly for running interactive jobs. This is intended to provide a similar experience to the old “Unix servers” and interactive virtual machines through SLURM. The aim of this queue is to keep wait times short. This is achieved by using SLURM’s quality of service features to give these jobs higher priority and by limiting the resources a user can request at any one time. To know how to start an interactive session, go to our <a href="/sites/rc2/SitePages/Interactive-workloads.aspx">interactive workloads</a> guide.</td></tr><tr><td><span class="fontColorBlue"><strong>regular</strong></span></td><td>This queue is intended to run the bulk of traditional batch work. It is a throughput-oriented queue where users can submit large numbers of jobs. Maximum CPU and memory allocations are determined by the size of the largest nodes which may vary from time to time. Maximum wall times will be limited to 48 hours. Our <a href="/sites/rc2/SitePages/Getting-started-Slurm.aspx">getting started with Slurm</a> guide provides more information.</td></tr><tr><td><span class="fontColorBlue"><strong>long</strong></span></td><td>This queue allows for jobs to run for up to 2 weeks, but with fewer resources than regular.</td></tr><tr><td><span class="fontColorBlue"><strong>gpuq</strong></span></td><td>This queue is for jobs that require GPUs. Milton has 12 nodes, with up to 4 GPUs per node. Otherwise, the GPU queue is configured in the same way as the regular queue.</td></tr><tr><td><span class="fontColorBlue"><strong>bigmem</strong></span></td><td>This queue is for jobs that require big memory up to 1.4 TB and&nbsp;&nbsp;128 CPUs</td></tr></tbody></table></figure><p><br>Priority-ordered jobs are allocated nodes within a partition until the resources (nodes, processors, memory, etc) within that partition are exhausted. A job can specify a specific partition to run on, for example, partition <i><span class="fontColorThemeSecondary">gpuq</span></i> to run jobs requiring GPUs.</p>
<h3><span class="fontColorThemeSecondary">regular</span> is the default partition if no other partition is stated in the job submission</h3>
<p>The maximum resources you can request of each partition are as follows:</p><figure class="table canvasRteResponsiveTable tableCenterAlign" style="width:97.64%;" title="Table"><table class="filledHeaderTableStyleTheme ck-table-resized"><colgroup><col style="width:13.31%;"><col style="width:11.05%;"><col style="width:12%;"><col style="width:14.11%;"><col style="width:21.39%;"><col style="width:17%;"><col style="width:11.14%;"></colgroup><tbody><tr><td>Partition</td><td><strong>Max submitted jobs/user</strong></td><td>Max running jobs/user</td><td><strong>Max CPUs</strong></td><td><strong>Max mem (GB)</strong></td><td><strong>Max wall time</strong></td><td><strong>GPUs</strong></td></tr><tr><td><span class="fontColorThemeSecondary"><strong>interactive</strong></span></td><td>1</td><td>1</td><td>16</td><td>64</td><td>24 hours</td><td>0</td></tr><tr><td><span class="fontColorThemeSecondary"><strong>regular</strong></span></td><td>5000</td><td>5000</td><td>454</td><td>3000</td><td>48 hours</td><td>0</td></tr><tr><td><span class="fontColorThemeSecondary"><strong>gpuq</strong></span></td><td>&nbsp;</td><td>&nbsp;</td><td>192</td><td>998</td><td>48 hours</td><td>up to 8 P100/A30 on 2 nodes, or 1A100.&nbsp;</td></tr><tr><td><span class="fontColorThemeSecondary"><strong>gpuq_interactive</strong></span></td><td>1</td><td>1</td><td>12</td><td>62</td><td>10 hours</td><td>1 A10</td></tr><tr><td><span class="fontColorThemeSecondary"><strong>long</strong></span></td><td>500</td><td>&nbsp;</td><td>96</td><td>500</td><td>2 weeks</td><td>0</td></tr><tr><td><span class="fontColorThemeSecondary"><strong>bigmem</strong></span></td><td>500</td><td>&nbsp;</td><td>128</td><td>1400</td><td>48 hours</td><td>0</td></tr></tbody></table></figure><p><br>These limits will impact some users, however, no one will be prevented from running. Please contact <a href="mailto:research.computing@wehi.edu.au">Research Computing</a> if this is a problem for you.</p>
<p>SLURM will <strong>not run</strong> a job if the requested resources cannot be allocated.</p><p>If you have a job that won't run, check the queues of the <a href="http://dashboards.hpc.wehi.edu.au/d/s/slurm?orgId=1&amp;refresh=10s"><strong>SLURM dashboard</strong></a> to check resource availability.</p><p>If your job fails, SLURM writes an <strong>.out </strong>and <strong>.err</strong> file which respectively contains the output and errors caused by your script. Make sure you investigate these files and edit your script accordingly before rerunning your script.</p><p>&nbsp;</p>
<h2><span class="fontColorThemeSecondary">SLURM Bonus QoS</span>​​​​​​​</h2>
<p>For efficient use of resources and to avoid idle resources, we have a bonus QoS, where&nbsp;users can run extra jobs even if they have already reached the limits of the partition. However, <strong>jobs submitted using this QoS can be preempted by non-bonus jobs if the non-bonus job is higher priority</strong>. This means that you must design your Slurm jobs to be restartable or make use of checkpoints.</p><p>This is subject<span class="fontColorBlue">&nbsp;</span>to the condition that</p><ul><li><strong>the resources requested are free at the time of submission</strong></li></ul><p>And the job can be canceled if</p><ul><li><strong>another job (which has not exceeded the partition limits, and not associated with a bonus QoS), requests those resources</strong></li></ul><p>Add this line to your submission script</p><pre>#SBATCH --qos=bonus</pre><p>Or&nbsp;</p><pre>--qos=bonus</pre><p>to your salloc/sbatch command.</p>
<h3><span class="fontColorThemeSecondary">How to get your jobs that had been preempted today?</span></h3><pre>sacct -X -u &lt;username&gt; --start today --end now --state=PREEMPTED</pre><p>Or for short</p><pre>sacct -X -u &lt;username&gt; -S today -E now -s PR</pre><h3><span class="fontColorThemeSecondary">How to know your job was preempted?</span></h3><p>When your job is preempted, you will find an error message in your logs similar to</p><pre>slurmstepd: error: *** JOB 7112846 ON gpu-a100-n01 CANCELLED AT 2022-07-04T16:36:52 DUE TO <span class="highlightColorYellow">PREEMPTION</span> ***<br> </pre>
<h2><span class="fontColorThemeSecondary">Milton SLURM Nodes</span></h2><p>See our <a href="/sites/rc2/SitePages/Milton-hardware.aspx">Milton Infrastructure page</a> to get an up-to-date inventory of the hardware available on Milton.</p>
<figure class="table tableCenterAlign canvasRteResponsiveTable" style="width:795px;" title="Table"><table class="ck-table-resized"><colgroup><col style="width:7.81%;"><col style="width:92.19%;"></colgroup><tbody><tr><td><p style="text-align:center;"><span class="fontColorRed"><strong>Note:</strong></span></p></td><td>The resources dedicated to SLURM vary according to operational requirements.</td></tr></tbody></table></figure>
