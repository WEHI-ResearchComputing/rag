<h2>SLURM frequently asked questions</h2><p>This page contains some of the frequently asked questions we receive about Slurm. If there is any question you would like answered that does not feature on this page, please contact <a href="mailto:research.computing@wehi.edu.au" data-cke-saved-href="mailto:research.computing@wehi.edu.au" target="_blank" data-interception="off" title="mailto:research.computing@wehi.edu.au">research.computing@wehi.edu.au</a> and let us know.</p>
<p style="margin-left:0px;margin-right:0px;text-align:start;"><span class="fontColorYellowLight"><strong>Is there a limit to the number of jobs that can be run?</strong></span></p><p style="margin-left:0px;margin-right:0px;text-align:start;"><span><span><span>Yes, 10000.</span></span></span></p><p style="margin-left:0px;margin-right:0px;text-align:start;"><span class="fontColorYellowLight"><strong>Is there a limit to the number of cores we can use?</strong></span></p><p style="margin-left:0px;margin-right:0px;text-align:start;"><span><span><span>Yes, each user can use up to 30% of the resources available in Slurm's regular queue. This means a user can use up to cpu=994, mem=5952G.</span></span></span></p><p style="margin-left:0px;margin-right:0px;text-align:start;"><span class="fontColorYellowLight"><strong>What happens when you hit this limit?</strong></span></p><p style="margin-left:0px;margin-right:0px;text-align:start;"><span><span><span>You can still submit jobs but they won't be run unless your other jobs finish. Therefore new jobs will be in the Pending state.</span></span></span></p><p style="margin-left:0px;margin-right:0px;text-align:start;"><span class="fontColorYellowLight"><strong>What is the largest job that can run?</strong></span></p><p style="margin-left:0px;margin-right:0px;text-align:start;"><span><span>The largest single node job is: <span class="fontColorBlueLight"><strong>cpu=128</strong></span>, <span class="fontColorBlueLight"><strong>mem=1.3TB</strong></span>, but there are only a few of these nodes, so large jobs may stay in a pending state in the queue until other jobs have finished. The SLURM scheduling uses a FAIR share algorithm to ensure all jobs run.</span></span></p><p><span class="fontColorYellowLight"><strong>How many GPUs can I use?</strong></span></p><p>Our page <a title="https://wehieduau.sharepoint.com/sites/rc2/SitePages/GPUs-on-Milton.aspx" data-interception="off" data-cke-saved-href="https://wehieduau.sharepoint.com/sites/rc2/SitePages/GPUs-on-Milton.aspx" href="/sites/rc2/SitePages/GPUs-on-Milton.aspx"><span class="fontColorYellow">GPUs on Milton</span></a> provides a table that explains this in detail.</p>
