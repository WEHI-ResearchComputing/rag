<h2>Guppy</h2><p>Guppy is a software released and maintained by Oxford Nanopore Technologies. It performs basecalling specifically for Nanopore sequencing signals as well as some post-processing steps.</p><p>Guppy is available on Milton through the guppy-cpu and guppy-gpu modules. The former being able to run on CPUs on any node, and the latter to be run on GPUs only.</p><pre>$ module avail guppy\n----------------------------------------- /stornext/System/data/modulefiles/nvidia ------------------------------------------\nguppy-gpu/2.3.1          guppy-gpu/3.1.5          guppy-gpu/3.2.2          guppy-gpu/3.3.0          guppy-gpu/4.0.15\nguppy-gpu/2.3.7          guppy-gpu/3.2.1          guppy-gpu/3.2.4          guppy-gpu/3.6.1          guppy-gpu/6.2.1(default)\n\n--------------------------------------- /stornext/System/data/modulefiles/bioinf/its ----------------------------------------\nguppy-cpu/2.3.7           guppy-cpu/3.2.1           guppy-cpu/3.2.4           guppy-cpu/3.6.1\nguppy-cpu/3.1.5           guppy-cpu/3.2.2           guppy-cpu/3.3.0           guppy-cpu/4.0.15(default)\n</pre><h3><span class="fontColorThemeSecondary">Basecalling with Guppy</span></h3><p>On Milton, Guppy is used via the guppy_basecaller command, whose with basic syntax:</p><pre>guppy_basecaller -i &lt;input-path&gt; -s &lt;output-path&gt; -x 'cuda:&lt;gpuID(s)&gt;' -c &lt;model&gt;</pre><p>where &lt;input-path&gt; is searched for fast5 files, and output results are placed in &lt;output-path&gt;. NVIDIA GPUs are specified by ID e.g. 0 or 2. &lt;model&gt; is the model used to translate signals into bases. For example</p><pre>guppy_basecaller -i pea_DNA -s pea_DNA_guppy_output -x 'cuda:all' -c dna_r10.4.1_e8.2_400bps_sup.cfg</pre><p>which uses the dna_r10.4.1_e8.2_400bps_sup.cfg model. the 'cuda:all' statement tells guppy to automatically use all visible GPUs. Note that inside a Slurm job, only the requested GPUs will be visible and usable.</p><h4>Splitting large datasets</h4><p>For large datasets, you can increase throughput by submitting multiple Slurm jobs using Guppy basecaller. This can be done by subdividing the fast5 input files and having each job work on these subdirecteries. This would mean that output files also need to be in different directories and joined afterward.</p><h4>Resuming</h4><p>If a Guppy job fails or times out, you can use the --resume option. This option tells the Guppy basecaller to continue where the previous run left off, assuming the output directory specified with "-s" contains incomplete results. For example</p><pre>guppy_basecaller -i pea_DNA -s pea_DNA_guppy_output -x 'cuda:all' -c dna_r10.4.1_e8.2_400bps_sup.cfg --resume</pre><p>And Guppy will continue where it failed, instead of starting from the very beginning and overwriting existing results. This can also be useful if you do not wish to split inputs and join results afterward.</p><h3><span class="fontColorThemeSecondary">Guppy Basecalling Performance</span></h3><h4>Multiple GPUs</h4><p>To utilise multiple GPUs with Guppy, you must first ensure the -x 'cuda:all' option is supplied to the command. This ensures All GPUs requested will be used by Guppy.</p><p>Secondly, you must also pass the --num_callers=&lt;nGPUs&gt; option to ensure Guppy properly utilizes the GPUs. For example, to use all 4 A30 GPUs on a single node, your Slurm script might look like.</p><pre>#!/bin/bash\n#SBATCH --cpus-per-task=16\n#SBATCH --mem=160G\n#SBATCH --partition=gpuq\n#SBATCH --gres=gpu:A30:4\n\nmodule load guppy-gpu/6.2.1\nguppy_basecaller -i pea_DNA -s pea_DNA_basecalled -c dna_r10.4.1_e8.2_400bps_sup.cfg \\\n-x 'cuda:all' \\ # ensures all GPUs requested are used\n--num_callers=4 # ensures parallel "callers" are started for each GPU\n</pre><h4>How many CPUs and how much memory to request?</h4><p>The number of CPUs Guppy can utilise scales linearly with the number of GPUs, but also depends on the accuracy of the model being used. For SUP models run on Milton's A30 and A100 GPU nodes, a good ratio of CPUs to GPUs is 4:1. So, if you request 2 GPUs, you should pass --cpus-per-task=8 and if you request 3, then you pass --cpus-per-task=12 etc. This ratio should ensure that Guppy performance isn't bottlenecked by the number of CPU cores, while also not unnecessarily occupying too many of a node's available CPU cores. 50GB of memory per GPU should provide plenty of memory for both A30s and A100s (these are <em>very</em> conservative numbers to avoid your job failing).</p><p>We generally recommend against using the P100 GPU nodes due to the significantly worse performance. However, if you wish to use them, a generally good ratio to maintain is 4 CPUs and 30G per GPU. These ratios are also constrained by the CPU cores and RAM available on the nodes.</p><h4>Tuning Performance</h4><p>guppy_basecaller has the additional option --chunks_per_runner which controls some of the data loading and transfer behaviours between the CPU and GPU(s). <strong>The optimal value will differ depending on your data, the model, and the model accuracy being used. To get help optimising this value to accelerate your work, <a href="mailto:research.computing@wehi.edu.au" data-cke-saved-href="mailto:research.computing@wehi.edu.au" data-interception="on" title="mailto:research.computing@wehi.edu.au">contact us</a>.</strong></p><p>For example, we have tested passing different values to these options on Milton's GPUs, and the following recommendations have been synthesised (tested with dna_r10.4.1_e8.2_400bps HAC and SUP models).</p><div class="canvasRteResponsiveTable"><div class="tableCenterAlign tableWrapper"><table class="bandedRowColumnTableStyleTheme cke_show_border"><tbody><tr><td role="columnheader"><br></td><td role="columnheader">P100-HAC</td><td role="columnheader">P100-SUP</td><td role="columnheader" style="width:77px;">A30-HAC</td><td role="columnheader" style="width:73px;">A30-SUP</td><td role="columnheader">A100-HAC</td><td role="columnheader">A100-SUP</td></tr><tr><td role="rowheader">--chunks_per_runner</td><td>512</td><td>256</td><td style="width:77px;">1280</td><td style="width:73px;">512</td><td>1280</td><td><p>512</p></td></tr></tbody></table></div></div><p>For example, calling guppy on 2x A100s using the SUP model, our command would become</p><pre>guppy_basecaller -i pea_DNA -s pea_DNA_basecalled -c dna_r10.4.1_e8.2_400bps_sup.cfg -x 'cuda:all' --num_callers 2 --chunks_per_runner 512</pre><h3><span class="fontColorThemeSecondary">Basecalling with Dorado</span></h3><p>Dorado is a basecaller also released by Oxford Nanopore Technologies. The tool is open-source and has significant performance improvements over Guppy, including the use of the more compact pod5 data format. See <a href="/sites/rc2/SitePages/ONT-dorado.aspx" data-cke-saved-href="https://wehieduau.sharepoint.com/sites/rc2/SitePages/ONT-dorado.aspx" data-interception="on" title="https://wehieduau.sharepoint.com/sites/rc2/SitePages/ONT-dorado.aspx">this page</a> for more information.<br></p>
