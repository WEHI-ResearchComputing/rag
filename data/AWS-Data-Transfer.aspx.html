<h2>Transferring data using AWS</h2><p>In this article, we will discuss how to securely transfer large amounts of data through AWS S3 buckets&nbsp;and the AWS CLI.</p>
<h3><span class="fontColorThemeSecondary">User requirements</span></h3><h4><span class="fontColorBlue">IAM accounts</span></h4><p>Each user that intends to access the bucket needs to have an IAM account.&nbsp;</p><ol><li><p>Sign in to the AWS Management Console and open the IAM console at&nbsp;<a data-cke-saved-href="https://console.aws.amazon.com/iam/" href="https://console.aws.amazon.com/iam/" target="_blank" title="https://console.aws.amazon.com/iam/" data-interception="off">console.aws.amazon.com/iam/</a></p></li><li><p>In the navigation pane, choose&nbsp;<b>Users</b>, then <b>Add users</b>.</p></li><li><p>Type the username for the new user. This is the AWS sign-in name.&nbsp;</p></li><li><p>Select the type of access this set of users will have. You can select programmatic access, access to the AWS Management Console, or both. For transferring small amounts of data, console access is enough but to transfer large amounts, programmatic access is required.</p><ul><li><p>Select&nbsp;<span class="fontColorBlue"><b>Programmatic access</b></span>&nbsp;if the users require access to the API, AWS CLI, or Tools for Windows PowerShell. This creates an access key for each new user. You can view or download the access keys when you get to the&nbsp;<b>Final</b>&nbsp;page.</p></li><li><p>Select&nbsp;<span class="fontColorBlue"><b>AWS Management Console access</b></span>&nbsp;if the users require access to the AWS Management Console. This creates a password for each new user.</p></li><li><p>For&nbsp;<span class="fontColorBlue"><b>Console password</b></span>, choose one of the following:</p><ul><li><p><b>Autogenerated password</b>. Each user gets a randomly generated password that meets the&nbsp;<a data-cke-saved-href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html" target="_blank" title="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_passwords_account-policy.html" data-interception="off">account password policy</a>. You can view or download the passwords when you get to the&nbsp;<b>Final</b>&nbsp;page.</p></li><li><p><b>Custom password</b>. Each user is assigned the password that you type in the box.</p></li></ul></li></ul></li><li><p>Choose&nbsp;<b>Next: Permissions</b>.</p></li><li><p>On the&nbsp;<b>Set permissions</b>&nbsp;page, specify how you want to assign permissions to this set of new users. Choose one of the following three options that allow the users to access S3 buckets:</p><ul><li><p><b>Add user to group</b>&nbsp;- that already has S3 permissions&nbsp;</p></li><li><p><b>Copy permissions from existing user&nbsp;</b>- that already has S3 permissions&nbsp;</p></li><li><p><b>Attach existing policies directly</b></p><ul style="margin-left:40px;"><li><p><b>​​​​​​​</b>Search and tick to attach the policy "<a data-cke-saved-href="https://us-east-1.console.aws.amazon.com/iam/home#/policies/arn%3Aaws%3Aiam%3A%3Aaws%3Apolicy%2FAmazonS3FullAccess" href="https://us-east-1.console.aws.amazon.com/iam/home#/policies/arn:aws:iam::aws:policy/AmazonS3FullAccess">AmazonS3FullAcces</a>s"</p></li><li>​​​​<strong>​​​</strong></li></ul></li></ul></li><li><p>Choose&nbsp;<b>Next: Tags</b>.</p></li><li><p>(Optional) Add metadata to the user by attaching tags as key-value pairs. For more information about using tags in IAM, see&nbsp;<a data-cke-saved-href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_tags.html" href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_tags.html" target="_blank" title="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_tags.html" data-interception="off">Tagging IAM resources</a>.</p></li><li><p>Choose&nbsp;<b>Next: Review</b>&nbsp;to see all of the choices you made up to this point. When you are ready to proceed, select <b>Create user</b>.</p></li><li><p>To view the users' access keys (access key IDs and secret access keys), choose&nbsp;<b>Show</b>&nbsp;next to each password and access key that you want to see. To save the access keys, choose&nbsp;<b>Download.csv</b>&nbsp;and save the file to a safe location. These are essential for using AWS CLI.</p></li></ol><h3><span class="fontColorThemeSecondary">Bucket creation</span></h3><p>S3 bucket is scalable so a regular bucket is&nbsp;</p><ol><li><p>Choose&nbsp;<b>Create bucket</b>.</p><p>The&nbsp;<b>Create bucket</b>&nbsp;wizard opens.</p></li><li><p>In&nbsp;<b>Bucket name</b>, enter a DNS-compliant name for your bucket.</p><p>The bucket name must:</p><ul><li><p>Be unique across all of Amazon S3.</p></li><li><p>Be between 3 and 63 characters long.</p></li><li><p>Not contain uppercase characters.</p></li><li><p>Start with a lowercase letter or number.</p></li></ul><p>After you create the bucket, you cannot change its name.&nbsp;</p></li><li><p>In&nbsp;<b>Region</b>, choose the AWS Region where you want the bucket to reside</p></li><li><p>Under&nbsp;<b>Object Ownership</b>, select ACLs disabled</p></li><li><p>In&nbsp;<b>Bucket settings for Block Public Access</b>, choose the Block All Public Access (all selected)</p></li><li><p>Choose&nbsp;<b>Create bucket</b>.</p></li></ol><h3><span class="fontColorThemeSecondary">Authentication</span></h3><p>There are two ways to authenticate users and allow them access to the bucket. The first is by using their user ARN, the second is by allowing certain IP addresses access to the bucket. The first is more secure because for example, every laptop that is connected to the WEHI network is internet facing on the same IP. Both solutions require the user to follow the User Requirements section below as that gives their IAM accounts access to complete action in the bucket. For ARN authentication follow the ARN section in Bucket ACLs, for IP authentication, follow the IP Address section.</p><h4><span class="fontColorBlue">User requirements</span></h4><p>Required from all users - user arn.<br>This can be found back in the IAM menus by clicking on the user that you need the arn for, it should look something like "arn:aws:iam::865452389153:user/bollands.c"</p><p>Whilst you are in the IAM menu for the user, select add inline policy and paste the following into the JSON tab for upload/download users respectfully in the action section:</p><pre>{\n    "Version": "2012-10-17",\n    "Statement": [\n        {\n            "Effect": "Allow",\n            "Action": [\n                "s3:PutObject"/"s3:GetObject",,\n                "s3:PutObjectAcl"/"s3:GetObjectAcl",\n                “s3:ListBucket”\n            ],\n            "Resource": [\n​​​​​​                "arn:aws:s3:::&lt;bucket-name&gt;",\n                "arn:aws:s3:::&lt;bucket-name&gt;/*"\n            ]\n        }\n​​​​​​​    ]\n}</pre><p style="text-align:start;"><br></p><p style="text-align:start;">If you want them to only be able to access certain folders replace</p><pre>"arn:aws:s3:::bucket-name",\n"arn:aws:s3:::bucket-name/*"\nWith\n"arn:aws:s3:::bucket-name/folder",\n"arn:aws:s3:::bucket-name/folder/*"</pre><h4><br><span class="fontColorBlue">Bucket Policies</span><br></h4><p style="text-align:start;"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>The bucket needs to have its policies configured so that users that don’t own the bucket can upload and download to it. The following inline policy needs to be added to the upload/download&nbsp;users respectively in the action section of the policy.</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>​​​​​​​</p><pre>{\n            "Version": "2012-10-17",\n            "Statement": [\n                        {\n                                    "Sid": "DelegateS3Access",\n                                    "Effect": "Allow",\n                                    "Principal": {\n                                                "AWS": "&lt;user-arn-here&gt;"\n                                    },\n                                    "Action": [\n                                                "s3:ListBucket",\n                                                "s3:PutObject"/"s3:GetObject",\n                                                "s3:PutObjectAcl"/"s3:GetObjectAcl"\n                                    ],\n                                    "Resource": [\n​​​​​​                                                "arn:aws:s3:::&lt;bucket-name-here&gt;",\n                                                "arn:aws:s3:::&lt;bucket-name-here&gt;/*"\n                                    ]\n                        }\n            ]\n}\n</pre><p><strong><em><u>IP Address</u></em></strong></p><p>You can configure the bucket policies so users from a specific IP address can upload or download to the specified bucket. This is not recommended for sensitive data because for example, everyone that connects to the bucket whilst routing through Global Protect for WEHI will have the same IP address.</p><p>The bucket needs to have its policies configured so that to allows access to a specific IP address.&nbsp;<span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>The following inline policy needs to be added to the upload/download&nbsp;users respectively in the action section of the policy.</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>​​​​​​​ The IP address for WEHI is&nbsp;128.250.252.193.</p><pre>{\n    "Version": "2012-10-17",\n    "Id": "Policy1415115909152",\n    "Statement": [\n        {\n            "Sid": "Access-to-specific-PublicIP-only",\n            "Effect": "Allow",\n            "Principal": "*",\n            "Action": [\n&nbsp;                      "s3:ListBucket", \n​​​​​​​                       "s3:PutObject"/"s3:GetObject",\n&nbsp;                      "s3:PutObjectAcl"/"s3:GetObjectAcl"\n            ​​​​​​​],\n            "Resource": [\n                "arn:aws:s3:::&lt;bucket name&gt;",\n                "arn:aws:s3:::&lt;bucket name&gt;/*"\n            ],\n            "Condition": {\n                "IpAddress": {\n                    "aws:SourceIp": "&lt;IP-address&gt;"\n                }\n            }\n        }\n    ]\n}</pre>
<h3 style="text-align:start;"><span class="fontColorThemeSecondary">Moving the data</span></h3><p style="text-align:start;"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>Moving small amounts of local data can simply be done by logging into the AWS console then dragging and dropping, or clicking upload/download the data into the bucket/to your local machine.</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:center;"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>For larger amounts of data or data on an HPC system, you will have to use the <strong><a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html%5c" data-cke-saved-href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html\\" data-interception="on" title="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html\\"><span class="fontColorBlue">aws cli</span></a></strong>. For downloading of the cli and configuration follow the link below. </span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><p style="text-align:start;"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>AWS cli is already installed on the <strong><a href="/sites/rc2/SitePages/modules.aspx" data-cke-saved-href="https://wehieduau.sharepoint.com/sites/rc2/SitePages/modules.aspx" data-interception="off" title="https://wehieduau.sharepoint.com/sites/rc2/SitePages/modules.aspx" target="_blank">Modules system</a></strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre style="margin-left:40px;">module load awscli</pre><p style="text-align:start;"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>​​​​​​​The action is the same both ways and this way it copies the data from place to place, rather than moving it, a safer option.</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><br><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>For example, moving a local folder from your HPC system to the bucket would be:</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre style="margin-left:40px;">aws s3 cp &lt;local_folder&gt; s3://bucket-name</pre><p style="text-align:start;"><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span><span>If you need to copy everything from a bucket that isn’t in a folder, you can use:</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p><pre style="margin-left:40px;">​​​​​​​aws s3 cp s3://&lt;bucket&gt; &lt;local_folder&gt; --recursive</pre><p>For moving large amounts of data it is recommended to use the sync command. This syncs the contents of the&nbsp;two directories which gives you a safety net of not having to copy all the data again if the connection drops. You can add --delete after sync to remove files that are in the target but not in the source.</p><pre style="margin-left:40px;">aws s3 sync &lt;local_folder&gt; s3://bucket-name\n\naws s3 sync --delete &lt;local_folder&gt; s3://bucket-name</pre><p><br></p><div class="canvasRteResponsiveTable"><div class="tableCenterAlign tableWrapper"><table style="width:770px;" class=" cke_show_border"><tbody><tr><td style="text-align:center;width:104px;"><strong>Command</strong></td><td style="text-align:center;width:613px;"><strong>Use</strong></td></tr><tr><td style="width:104px;">aws s3 mv</td><td style="width:613px;">Move the data from first location to second. This will mean there is no copy of the data in the original location. Breaks if connection drops.</td></tr><tr><td style="width:104px;">aws s3 cp</td><td style="width:613px;">Copy the data from the first location to the second. This means there is a copy of the data in the first and second location. Breaks if connection drops.</td></tr><tr><td style="width:104px;">aws s3 sync</td><td style="width:613px;">Synchronises the data from first location to second. This is effectively the same as the copy command however it only moves across data that is not in the target. If the command has --delete in it, it will also remove data in the target that is not in the source. Breaks if the connection drops but due to the nature of the command, running sync again will pick up where it left off.</td></tr></tbody></table></div></div><p>If you have any issues, please contact the RCP team.</p>
